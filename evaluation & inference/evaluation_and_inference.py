# -*- coding: utf-8 -*-
"""evaluation-and-inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h7I0UJSrhJwBojispHhtIdSh5k25S8vr
"""

# @markdown Mount Google Drive
from google.colab import drive

drive.mount('/content/drive')

# @title Load Dataset
import pandas as pd

file_path = "/content/drive/My Drive/diabetes_indicators.csv"

df = pd.read_csv(file_path)
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

df.head()

# @markdown Get Features
columns = df.columns

columns

# @title Discretize Continuous Variables
df['BMI'] = pd.cut(df['BMI'], bins=3, labels=[0, 1, 2])  # Low, Medium, High
df['Age'] = pd.cut(df['Age'], bins=3, labels=[0, 1, 2])  # Young, Middle, Old
df['MentHlth'] = pd.cut(df['MentHlth'], bins=2, labels=[0, 1])  # Good, Bad
df['PhysHlth'] = pd.cut(df['PhysHlth'], bins=2, labels=[0, 1])  # Good, Bad

"""## Parameter Learning (Estimate Probabilities)"""

from pgmpy.estimators import MaximumLikelihoodEstimator

# Define the Bayesian Model with learned structure
from pgmpy.models import BayesianNetwork
model = BayesianNetwork(best_model.edges())

# Learn CPDs
model.fit(df, estimator=MaximumLikelihoodEstimator)

for cpd in model.cpds:
    print(cpd)

"""### Simple Inference"""

from pgmpy.inference import VariableElimination

inference = VariableElimination(model)

# Example: P(Diabetes | HighBP=1, BMI=High)
prob_diabetes = inference.query(variables=["Diabetes_binary"], evidence={"HighBP": 1, "BMI": 2})
print(prob_diabetes)

"""### Visualize CPDs"""

print(model.get_cpds("Diabetes_binary"))

df_selected = pd.read_csv('df_selected.csv')

df = df_selected

df.columns

"""## Data Sampling"""

from sklearn.model_selection import train_test_split

df_sampled, _ = train_test_split(df, train_size=7000, stratify=df["Diabetes_binary"], random_state=42)

print(f"‚úÖ Sampled Data Shape: {df_sampled.shape}")

print("df info:")
print(df.info())

print("\ndf_sampled info:")
print(df_sampled.info())

"""## Evaluate Models (Without Feature Selection) and Find the Best"""

models["Na√Øve Bayes"] = naive_bayes_model
models["Simulated Annealing"] = best_model_sa

df.head()

df_sampled.head()

df_sampled = df_sampled.loc[:, ~df_sampled.columns.duplicated()]

from pgmpy.models import BayesianNetwork
from pgmpy.estimators import ExpectationMaximization
from pgmpy.inference import VariableElimination
from sklearn.metrics import roc_auc_score
import pandas as pd
import numpy as np

def preprocess_data(df_sampled):
    """
    Preprocess DataFrame with proper handling of both categorical and float columns
    """
    df_copy = df_sampled.copy()

    for col in df_copy.columns:
        try:
            if df_copy[col].dtype.name == 'category':
                # For categorical columns, just get their codes directly
                df_copy[col] = df_copy[col].cat.codes
            elif df_copy[col].dtype == 'float64':
                # For float columns, convert to int
                df_copy[col] = df_copy[col].astype(int)

            print(f"Successfully processed column: {col} (unique values: {len(df_copy[col].unique())})")

        except Exception as e:
            print(f"Error processing column '{col}': {e}")
            return None

    print("\nProcessed DataFrame info:")
    print(df_copy.info())
    return df_copy

def convert_to_bayesian_network(dag, df_sampled):
    """
    Convert a DAG to a Bayesian Network and learn CPDs using EM
    """
    print("Starting preprocessing...")
    df_processed = preprocess_data(df_sampled)

    if df_processed is None:
        raise ValueError("Preprocessing failed")

    print("\nSample of processed data:")
    print(df_processed.head())

    print("\nCreating Bayesian Network...")
    bn_model = BayesianNetwork(dag.edges())

    try:
        print("Fitting model with EM...")
        bn_model.fit(
            df_processed,
            estimator=ExpectationMaximization,
        )
        print("Model fitting complete!")

        if bn_model.check_model():
            print("‚úÖ Model structure is valid.")
        else:
            print("‚ö†Ô∏è Model structure is invalid.")

    except Exception as e:
        print("Error during fitting with EM:", str(e))
        raise e

    return bn_model

def evaluate_model(model, df_sampled):
    """
    Compute ROC AUC for a single model
    """
    df_processed = preprocess_data(df_sampled)
    if df_processed is None:
        raise ValueError("Preprocessing failed during evaluation")

    inference = VariableElimination(model)
    y_true = df_processed["Diabetes_binary"]

    y_pred = []
    for _, row in df_processed.iterrows():
        evidence = row.drop("Diabetes_binary").to_dict()
        try:
            result = inference.map_query(
                variables=["Diabetes_binary"],
                evidence=evidence
            )
            pred = result["Diabetes_binary"]
            y_pred.append(pred)
        except Exception as e:
            print(f"Inference error: {e}")
            y_pred.append(0)

    return roc_auc_score(y_true, y_pred)

def evaluate_all_models(models, df_sampled):
    """
    Evaluate all models and return their AUC scores
    """
    print("\nStarting model evaluation...")
    auc_scores = {}

    for name, dag in models.items():
        try:
            print(f"\nüîÑ Converting {name} to Bayesian Network...")
            bn_model = convert_to_bayesian_network(dag, df_sampled)
            print(f"‚úÖ {name} converted successfully!")

            print(f"üîç Evaluating {name}...")
            auc = evaluate_model(bn_model, df_sampled)
            auc_scores[name] = auc
            print(f"üéØ {name} AUC Score: {auc:.4f}")

        except Exception as e:
            print(f"‚ùå Error processing {name}: {str(e)}")

    if auc_scores:
        best_model_name = max(auc_scores, key=auc_scores.get)
        print(f"\nüèÜ Best Model: {best_model_name} with AUC = {auc_scores[best_model_name]:.4f}")
    else:
        print("\n‚ö†Ô∏è No models were successfully evaluated.")

    return auc_scores

if __name__ == "__main__":
    print("DataFrame information before processing:")
    print(df_sampled.info())

    results = evaluate_all_models(models, df_sampled)

import matplotlib.pyplot as plt

# Plot AUC Scores
plt.figure(figsize=(8,5))
plt.bar(results.keys(), results.values(), color=['yellow', 'green', 'purple', 'red', 'blue'])
plt.xlabel("Model Name")
plt.ylabel("AUC Score")
plt.title("Model (Before Feature Selection) Comparison Based on AUC")
plt.xticks(rotation=45)
plt.ylim(0.5, 1.0)  # AUC range
plt.show()

"""## Evaluate Models (After Feature Selection) and Find the Best"""

models["Na√Øve Bayes"] = naive_bayes_model
models["Simulated Annealing"] = best_model_sa

df_sampled = df_sampled.loc[:, ~df_sampled.columns.duplicated()]

df_sampled.columns

models['BIC'].nodes()

from sklearn.model_selection import train_test_split

df_train, df_test = train_test_split(df_sampled, test_size=0.2, random_state=42)

print(f"Training Set Size: {len(df_train)}")
print(f"Testing Set Size: {len(df_test)}")

from pgmpy.models import BayesianNetwork
from pgmpy.estimators import ExpectationMaximization
from pgmpy.inference import VariableElimination
from sklearn.metrics import roc_auc_score
import pandas as pd
import numpy as np

def preprocess_data(df_sampled):
    """
    Preprocess DataFrame with proper handling of both categorical and float columns
    """
    df_copy = df_sampled.copy()

    for col in df_copy.columns:
        try:
            if df_copy[col].dtype.name == 'category':
                # For categorical columns, just get their codes directly
                df_copy[col] = df_copy[col].cat.codes
            elif df_copy[col].dtype == 'float64':
                # For float columns, convert to int
                df_copy[col] = df_copy[col].astype(int)

            print(f"Successfully processed column: {col} (unique values: {len(df_copy[col].unique())})")

        except Exception as e:
            print(f"Error processing column '{col}': {e}")
            return None

    print("\nProcessed DataFrame info:")
    print(df_copy.info())
    return df_copy

def convert_to_bayesian_network(dag, df_sampled):
    """
    Convert a DAG to a Bayesian Network and learn CPDs using EM
    """
    print("Starting preprocessing...")
    df_processed = preprocess_data(df_sampled)

    if df_processed is None:
        raise ValueError("Preprocessing failed")

    print("\nSample of processed data:")
    print(df_processed.head())

    print("\nCreating Bayesian Network...")
    bn_model = BayesianNetwork(dag.edges())

    try:
        print("Fitting model with MLE...")
        bn_model.fit(
        df_processed, estimator=MaximumLikelihoodEstimator, state_names=True
        )
        print("Model fitting complete!")

        if bn_model.check_model():
            print("‚úÖ Model structure is valid.")
        else:
            print("‚ö†Ô∏è Model structure is invalid.")

    except Exception as e:
        print("Error during fitting with EM:", str(e))
        raise e

    for cpd in bn_model.get_cpds():
        print(f"üîç Checking {cpd.variable}: Sum = {cpd.values.sum()}")

    return bn_model

def evaluate_model(model, df_sampled):
    """
    Compute ROC AUC for a single model
    """
    df_processed = preprocess_data(df_sampled)
    if df_processed is None:
        raise ValueError("Preprocessing failed during evaluation")

    inference = VariableElimination(model)
    y_true = df_processed["Diabetes_binary"]

    y_pred = []
    for _, row in df_processed.iterrows():
        evidence = row.drop("Diabetes_binary").to_dict()
        try:
            result = inference.map_query(
                variables=["Diabetes_binary"],
                evidence=evidence
            )
            pred = result["Diabetes_binary"]
            y_pred.append(pred)
        except Exception as e:
            print(f"Inference error: {e}")
            y_pred.append(0)

    return roc_auc_score(y_true, y_pred)

def evaluate_all_models(models, df_train, df_test):

    print("\nüöÄ Starting model training and evaluation...")

    auc_scores = {}

    for name, dag in models.items():
        try:
            print(f"\nüîÑ Training {name} on TRAIN set...")
            bn_model = convert_to_bayesian_network(dag, df_train)
            print(f"‚úÖ {name} trained successfully!")

            print(f"üîç Evaluating {name} on TEST set...")
            auc = evaluate_model(bn_model, df_test)
            auc_scores[name] = auc
            print(f"üéØ {name} AUC Score (Test Set): {auc:.4f}")

        except Exception as e:
            print(f"‚ùå Error processing {name}: {str(e)}")

    if auc_scores:
        best_model_name = max(auc_scores, key=auc_scores.get)
        print(f"\nüèÜ Best Model: {best_model_name} with AUC = {auc_scores[best_model_name]:.4f}")
    else:
        print("\n‚ö†Ô∏è No models were successfully evaluated.")

    return auc_scores

if __name__ == "__main__":
    print("DataFrame information before processing:")
    print(df_sampled.info())

    results = evaluate_all_models(models, df_train, df_test)

import matplotlib.pyplot as plt

# Plot AUC Scores
plt.figure(figsize=(8,5))
plt.bar(results.keys(), results.values(), color=['yellow', 'green', 'red', 'purple', 'blue'])
plt.xlabel("Model Name")
plt.ylabel("AUC Score")
plt.title("Model (After Feature Selection) Comparison Based on AUC")
plt.xticks(rotation=45)
plt.ylim(0.5, 1.0)  # AUC range
plt.show()

"""## Evaluate Domain Knowledge-based Model"""

bn_domain_knowledge.nodes()

domain_knowledge_features_list = list(bn_domain_knowledge.nodes())

df_selected_domain_knowledge = df[domain_knowledge_features_list]

df_selected_domain_knowledge.head()

from sklearn.model_selection import train_test_split

df_sampled_d, _ = train_test_split(df_selected_domain_knowledge, train_size=12000, stratify=df["Diabetes_binary"], random_state=42)

print(f"‚úÖ Sampled Data Shape: {df_sampled_d.shape}")

df_sampled_d = df_sampled_d.loc[:, ~df_sampled_d.columns.duplicated()]

from sklearn.model_selection import train_test_split

df_train_d, df_test_d = train_test_split(df_sampled_d, test_size=0.2, random_state=42)

from pgmpy.models import BayesianNetwork
from pgmpy.estimators import ExpectationMaximization
from pgmpy.inference import VariableElimination
from sklearn.metrics import roc_auc_score
from pgmpy.estimators import MaximumLikelihoodEstimator
import pandas as pd
import numpy as np

def preprocess_data(df_sampled):
    """
    Preprocess DataFrame with proper handling of both categorical and float columns
    """
    df_copy = df_sampled.copy()

    for col in df_copy.columns:
        try:
            if df_copy[col].dtype.name == 'category':
                # For categorical columns, just get their codes directly
                df_copy[col] = df_copy[col].cat.codes
            elif df_copy[col].dtype == 'float64':
                # For float columns, convert to int
                df_copy[col] = df_copy[col].astype(int)

            print(f"Successfully processed column: {col} (unique values: {len(df_copy[col].unique())})")

        except Exception as e:
            print(f"Error processing column '{col}': {e}")
            return None

    print("\nProcessed DataFrame info:")
    print(df_copy.info())
    return df_copy

def convert_to_bayesian_network(dag, df_sampled):
    """
    Convert a DAG to a Bayesian Network and learn CPDs using EM
    """
    print("Starting preprocessing...")
    df_processed = preprocess_data(df_sampled)

    if df_processed is None:
        raise ValueError("Preprocessing failed")

    print("\nSample of processed data:")
    print(df_processed.head())

    print("\nCreating Bayesian Network...")
    bn_model = BayesianNetwork(dag.edges())

    try:
        print("Fitting model with MLE...")
        bn_model.fit(
        df_processed, estimator=MaximumLikelihoodEstimator, state_names=True
        )
        print("Model fitting complete!")

        if bn_model.check_model():
            print("‚úÖ Model structure is valid.")
        else:
            print("‚ö†Ô∏è Model structure is invalid.")

    except Exception as e:
        print("Error during fitting with EM:", str(e))
        raise e

    return bn_model

def evaluate_model(model, df_sampled):
    """
    Compute ROC AUC for a single model
    """
    df_processed = preprocess_data(df_sampled)
    if df_processed is None:
        raise ValueError("Preprocessing failed during evaluation")

    inference = VariableElimination(model)
    y_true = df_processed["Diabetes_binary"]

    y_pred = []
    for _, row in df_processed.iterrows():
        evidence = row.drop("Diabetes_binary").to_dict()
        try:
            result = inference.map_query(
                variables=["Diabetes_binary"],
                evidence=evidence
            )
            pred = result["Diabetes_binary"]
            y_pred.append(pred)
        except Exception as e:
            print(f"Inference error: {e}")
            y_pred.append(0)

    return roc_auc_score(y_true, y_pred)

def evaluate_all_models(dag, df_train, df_test):

    print("\nüöÄ Starting model training and evaluation...")

    auc_scores = {}

    print(f"\nüîÑ Training on TRAIN set...")
    bn_model = convert_to_bayesian_network(dag, df_train)
    print(f"‚úÖ trained successfully!")

    print(f"üîç Evaluating on TEST set...")
    auc = evaluate_model(bn_model, df_test)
    auc_scores = auc
    print(f"üéØ AUC Score (Test Set): {auc:.4f}")

    return auc_scores

if __name__ == "__main__":
    print("DataFrame information before processing:")
    print(df_sampled_d.info())

    results = evaluate_all_models(bn_domain_knowledge, df_train_d, df_test_d)

"""## Parameter Estimation for the Best Structures & Do Inference

### Domain Knowledge-based Best Model
"""

from pgmpy.estimators import MaximumLikelihoodEstimator

bn_d = BayesianNetwork(bn_domain_knowledge.edges())

df_processed = preprocess_data(df_selected_domain_knowledge)

print("‚öôÔ∏è Learning parameters using MLE for K2...")
bn_d.fit(df_processed, estimator=MaximumLikelihoodEstimator)
print("‚úÖ Parameter learning complete!")

# Print learned CPDs (Conditional Probability Distributions)
for cpd in bn_d.get_cpds():
    print(f"\nCPD for {cpd.variable}:")
    print(cpd)

best_model = bn_d

# @markdown Save Best Model
import pickle

with open("best_model_domain_knowledge.pkl", "wb") as file:
    pickle.dump(best_model, file)

print("‚úÖ Model saved as best_model_domain_knowledge.pkl")

# @markdown Dave Best Model to Drive
import pickle

save_path = "/content/drive/My Drive/best_model_domain_knowledge.pkl"

with open(save_path, "wb") as f:
    pickle.dump(bn_d, f)
print(f"‚úÖ Model saved to Google Drive at: {save_path}")

# @markdown Load Best Model
import pickle

with open("best_model_domain_knowledge.pkl", "rb") as f:
    loaded_model = pickle.load(f)
print("‚úÖ Model loaded successfully!")

loaded_model.edges()

loaded_model.get_cpds()  # Print conditional probability distributions (CPDs)

loaded_model.check_model()

"""#### A Basic Inference"""

from pgmpy.inference import VariableElimination

inference = VariableElimination(loaded_model)

""" this evidence is about a person who:
 Has high blood pressure, BMI lower than normal,
 Bad general health state, Age in the old category (older than 60),
 female, with annual income: less than $35,000
"""
evidence = {"HighBP": 1, "BMI": 0, "GenHlth": 5, "Age": 2, "Sex": 0, "Income": 5}

result = inference.query(variables=["Diabetes_binary"], evidence=evidence)
print(result)

"""### AI-based Best Model (Hill Climbing K2)"""

from pgmpy.estimators import MaximumLikelihoodEstimator

bn_k2 = BayesianNetwork(models['K2'].edges())

df_processed = preprocess_data(df)

print("‚öôÔ∏è Learning parameters using MLE for K2...")
bn_k2.fit(df_processed, estimator=MaximumLikelihoodEstimator)
print("‚úÖ Parameter learning complete!")

# Print learned CPDs (Conditional Probability Distributions)
for cpd in bn_k2.get_cpds():
    print(f"\nCPD for {cpd.variable}:")
    print(cpd)

best_model = bn_k2

# @markdown Save Best Model
import pickle

with open("best_model_as.pkl", "wb") as file:
    pickle.dump(best_model, file)

print("‚úÖ Model saved as best_model_as.pkl")

# @markdown Dave Best Model to Drive
import pickle

save_path = "/content/drive/My Drive/best_model_as.pkl"

with open(save_path, "wb") as f:
    pickle.dump(bn_k2, f)
print(f"‚úÖ Model saved to Google Drive at: {save_path}")

# @markdown Load Best Model
import pickle

with open("best_model_as.pkl", "rb") as f:
    loaded_model = pickle.load(f)
print("‚úÖ Model loaded successfully!")

loaded_model.edges()

loaded_model.get_cpds()  # Print conditional probability distributions (CPDs)

loaded_model.check_model()

df_selected.columns

from pgmpy.inference import VariableElimination

inference = VariableElimination(loaded_model)

evidence = {"HighBP": 1, "BMI": 0, "GenHlth": 5, "Age": 2, "Sex": 0, "Income": 5}

result = inference.query(variables=["Diabetes_binary"], evidence=evidence)
print(result)